{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnOCRwTbFH9tObKaKv1jIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balaji4397/8-puzzle-Solver/blob/main/Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_mRA6LLj10l",
        "outputId": "afb22a29-1ff5-4e34-f03c-7e2a0b1c3860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=1818aa628450af494675acd6cb4d533c54aa5854d91944f3728161923a6d18bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession,functions as f\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "from pyspark.sql import Window"
      ],
      "metadata": {
        "id": "jQoBRqeVkSP6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkSession.Builder().appName('sample').master('local[5]').getOrCreate()\n",
        "data = [\n",
        "    (1, \"Gilbert Gathara\", \"24\", \"Nairobi\"),\n",
        "    (2, \"Someone Else\", \"32\", \"Nowhere\")\n",
        "]\n",
        "headers = (\"id\", \"Name\", \"Age\", \"Location\")\n",
        "df = sc.createDataFrame(data, headers)\n",
        "df.show()\n",
        "df=df.drop('Location')\n",
        "df.show()\n",
        "data2 = [[3,'Balaji',27],[4,'srikar',31]]\n",
        "df2=sc.createDataFrame(data2, [\"id\", \"Name\", \"Age\"])\n",
        "df2.show()\n",
        "df = df.union(df2)\n",
        "df.show()\n",
        "location=['USA','Europe','India','India']\n",
        "loc_df = sc.createDataFrame([(l,) for l in location], ['location'])\n",
        "loc_df.show()\n",
        "a = df.withColumn(\"x\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "b = loc_df.withColumn(\"x\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "\n",
        "final_df = a.join(b, a.x == b.x).drop(\"x\")\n",
        "final_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQwOxoTsGZAM",
        "outputId": "b8b1cd23-14a0-4a95-c06b-6bc1d142fb03"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+---+--------+\n",
            "| id|           Name|Age|Location|\n",
            "+---+---------------+---+--------+\n",
            "|  1|Gilbert Gathara| 24| Nairobi|\n",
            "|  2|   Someone Else| 32| Nowhere|\n",
            "+---+---------------+---+--------+\n",
            "\n",
            "+---+---------------+---+\n",
            "| id|           Name|Age|\n",
            "+---+---------------+---+\n",
            "|  1|Gilbert Gathara| 24|\n",
            "|  2|   Someone Else| 32|\n",
            "+---+---------------+---+\n",
            "\n",
            "+---+------+---+\n",
            "| id|  Name|Age|\n",
            "+---+------+---+\n",
            "|  3|Balaji| 27|\n",
            "|  4|srikar| 31|\n",
            "+---+------+---+\n",
            "\n",
            "+---+---------------+---+\n",
            "| id|           Name|Age|\n",
            "+---+---------------+---+\n",
            "|  1|Gilbert Gathara| 24|\n",
            "|  2|   Someone Else| 32|\n",
            "|  3|         Balaji| 27|\n",
            "|  4|         srikar| 31|\n",
            "+---+---------------+---+\n",
            "\n",
            "+--------+\n",
            "|location|\n",
            "+--------+\n",
            "|     USA|\n",
            "|  Europe|\n",
            "|   India|\n",
            "|   India|\n",
            "+--------+\n",
            "\n",
            "+---+---------------+---+--------+\n",
            "| id|           Name|Age|location|\n",
            "+---+---------------+---+--------+\n",
            "|  1|Gilbert Gathara| 24|     USA|\n",
            "|  2|   Someone Else| 32|  Europe|\n",
            "|  3|         Balaji| 27|   India|\n",
            "|  4|         srikar| 31|   India|\n",
            "+---+---------------+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "sc=SparkSession.Builder().appName('emptydataframe').getOrCreate()\n",
        "schema = StructType([\n",
        "    StructField('S.no',IntegerType(),True),\n",
        "    StructField('Name',StringType(),True),\n",
        "    StructField('Age', IntegerType(),True)\n",
        "])\n",
        "df = sc.createDataFrame([],schema)\n",
        "df.show()\n",
        "data = [(1,'balaji',26),(2,'srikar',31),(3,'sam',39)]\n",
        "headers = ('S.no','Name','Age')\n",
        "join_df = sc.createDataFrame(data, headers)\n",
        "df = df.union(join_df)\n",
        "df.show()\n",
        "location=['lafayette','BR','BR']\n",
        "loc_df = sc.createDataFrame([(l,) for l in location],['location'])\n",
        "loc_df.show()\n",
        "df = df.withColumn('x',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "loc_df = loc_df.withColumn('x',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "df = df.join(loc_df, df.x == loc_df.x).drop('x')\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nXJ9jUTO14e",
        "outputId": "d4475b26-c0a5-4126-8db5-6f67911699ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---+\n",
            "|S.no|Name|Age|\n",
            "+----+----+---+\n",
            "+----+----+---+\n",
            "\n",
            "+----+------+---+\n",
            "|S.no|  Name|Age|\n",
            "+----+------+---+\n",
            "|   1|balaji| 26|\n",
            "|   2|srikar| 31|\n",
            "|   3|   sam| 39|\n",
            "+----+------+---+\n",
            "\n",
            "+---------+\n",
            "| location|\n",
            "+---------+\n",
            "|lafayette|\n",
            "|       BR|\n",
            "|       BR|\n",
            "+---------+\n",
            "\n",
            "+----+------+---+---------+\n",
            "|S.no|  Name|Age| location|\n",
            "+----+------+---+---------+\n",
            "|   1|balaji| 26|lafayette|\n",
            "|   2|srikar| 31|       BR|\n",
            "|   3|   sam| 39|       BR|\n",
            "+----+------+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "sc= SparkSession.Builder().appName('Sample').master('local[5]').getOrCreate()\n",
        "schema = StructType([\n",
        "    StructField('ID', IntegerType(),True),\n",
        "    StructField('Name', StringType(),True),\n",
        "    StructField('Age', IntegerType(),True)\n",
        "])\n",
        "emptydf = sc.createDataFrame([],schema)\n",
        "data = [(1,'balaji',26),(2,'srikar',31),(3,'sam',39)]\n",
        "headers = ('ID','Name','Age')\n",
        "df=sc.createDataFrame(data, headers)\n",
        "df.show()\n",
        "df.printSchema()\n",
        "df = df.withColumn(\"ID\", df[\"ID\"].cast(IntegerType()))\n",
        "df.printSchema()\n",
        "location=['CA','LA','LA']\n",
        "loc_df=sc.createDataFrame([(l,) for l in location],['location'])\n",
        "loc_df.show()\n",
        "df = df.withColumn('x',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "loc_df = loc_df.withColumn('x',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "df = df.join(loc_df, df.x==loc_df.x).drop('x')\n",
        "df.show()\n",
        "df=df.withColumnRenamed('location','state')\n",
        "df.show()\n",
        "df2=sc.createDataFrame([[4,'ranga','31','YV']])\n",
        "df = df.union(df2)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8mES-GU04FV",
        "outputId": "4de3f426-48a4-4660-a355-c5eba5d99f33"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+\n",
            "| ID|  Name|Age|\n",
            "+---+------+---+\n",
            "|  1|balaji| 26|\n",
            "|  2|srikar| 31|\n",
            "|  3|   sam| 39|\n",
            "+---+------+---+\n",
            "\n",
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n",
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n",
            "+--------+\n",
            "|location|\n",
            "+--------+\n",
            "|      CA|\n",
            "|      LA|\n",
            "|      LA|\n",
            "+--------+\n",
            "\n",
            "+---+------+---+--------+\n",
            "| ID|  Name|Age|location|\n",
            "+---+------+---+--------+\n",
            "|  1|balaji| 26|      CA|\n",
            "|  2|srikar| 31|      LA|\n",
            "|  3|   sam| 39|      LA|\n",
            "+---+------+---+--------+\n",
            "\n",
            "+---+------+---+-----+\n",
            "| ID|  Name|Age|state|\n",
            "+---+------+---+-----+\n",
            "|  1|balaji| 26|   CA|\n",
            "|  2|srikar| 31|   LA|\n",
            "|  3|   sam| 39|   LA|\n",
            "+---+------+---+-----+\n",
            "\n",
            "+---+------+---+-----+\n",
            "| ID|  Name|Age|state|\n",
            "+---+------+---+-----+\n",
            "|  1|balaji| 26|   CA|\n",
            "|  2|srikar| 31|   LA|\n",
            "|  3|   sam| 39|   LA|\n",
            "|  4| ranga| 31|   YV|\n",
            "+---+------+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "sc = SparkSession.Builder().appName('sample').master('local[5]').getOrCreate()\n",
        "data = [(1,'balaji',26,'Lafayette'),(2,'srikar',31,'BR'),(3,'sam',39,'BR')]\n",
        "headers = ('ID','Name','Age')\n",
        "schema = StructType([\n",
        "    StructField('ID',IntegerType(),True),\n",
        "    StructField('Name',StringType(),True),\n",
        "    StructField('Age',StringType(),True),\n",
        "    StructField('Location',StringType(),True)\n",
        "])\n",
        "final_df = sc.createDataFrame(data, schema = schema)\n",
        "final_df.show()\n",
        "company_lst = ['CGI','Apple','Bayleaf']\n",
        "comp_df = sc.createDataFrame([(l,) for l in company_lst],['Company'])\n",
        "a = final_df.withColumn('x', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "b = comp_df.withColumn('x', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "df = a.join(b, a.x == b.x).drop('x')\n",
        "df.show()\n",
        "data2 = [[4,'Ranga',32,'YV','Non-IT']]\n",
        "data2_df = sc.createDataFrame(data2,schema=df.schema)\n",
        "data2_df.show()\n",
        "df = df.union(data2_df)\n",
        "df.show()\n",
        "df = df.withColumnRenamed('Location','Address')\n",
        "df.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vt7ZbOMX0Am",
        "outputId": "3e94f432-e17e-4a2a-fd7d-36d537fff1c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---------+\n",
            "| ID|  Name|Age| Location|\n",
            "+---+------+---+---------+\n",
            "|  1|balaji| 26|Lafayette|\n",
            "|  2|srikar| 31|       BR|\n",
            "|  3|   sam| 39|       BR|\n",
            "+---+------+---+---------+\n",
            "\n",
            "+---+------+---+---------+-------+\n",
            "| ID|  Name|Age| Location|Company|\n",
            "+---+------+---+---------+-------+\n",
            "|  1|balaji| 26|Lafayette|    CGI|\n",
            "|  2|srikar| 31|       BR|  Apple|\n",
            "|  3|   sam| 39|       BR|Bayleaf|\n",
            "+---+------+---+---------+-------+\n",
            "\n",
            "+---+-----+---+--------+-------+\n",
            "| ID| Name|Age|Location|Company|\n",
            "+---+-----+---+--------+-------+\n",
            "|  4|Ranga| 32|      YV| Non-IT|\n",
            "+---+-----+---+--------+-------+\n",
            "\n",
            "+---+------+---+---------+-------+\n",
            "| ID|  Name|Age| Location|Company|\n",
            "+---+------+---+---------+-------+\n",
            "|  1|balaji| 26|Lafayette|    CGI|\n",
            "|  2|srikar| 31|       BR|  Apple|\n",
            "|  3|   sam| 39|       BR|Bayleaf|\n",
            "|  4| Ranga| 32|       YV| Non-IT|\n",
            "+---+------+---+---------+-------+\n",
            "\n",
            "+---+------+---+---------+-------+\n",
            "| ID|  Name|Age|  Address|Company|\n",
            "+---+------+---+---------+-------+\n",
            "|  1|balaji| 26|Lafayette|    CGI|\n",
            "|  2|srikar| 31|       BR|  Apple|\n",
            "|  3|   sam| 39|       BR|Bayleaf|\n",
            "|  4| Ranga| 32|       YV| Non-IT|\n",
            "+---+------+---+---------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}